id: 696e4092f1dd2fc1624a167e_user_guide
summary: Case Study 5: AI-Powered Code Generation Risk Assessment + Secure SDLC Controls User Guide
feedback link: https://docs.google.com/forms/d/e/1FAIpQLSfWkOK-in_bMMoHSZfcIvAeO58PAH9wrDqcxnJABHaxiDqhSA/viewform?usp=sf_link
environments: Web
status: Published
# AI-Powered Code Generation Risk Assessment and Secure SDLC Controls

## 1. Understanding the Challenge and Solution
Duration: 00:05:00

Welcome to the QuLab: Case Study 5 Codelab on **AI-Powered Code Generation Risk Assessment + Secure SDLC Controls**.

<aside class="positive">
This codelab will guide you through an application designed to address a critical modern challenge: how to leverage the productivity gains of AI code assistants while simultaneously ensuring robust security. You will learn to proactively identify and mitigate security risks introduced by AI-generated code *before* they impact your production environment.
</aside>

As software development increasingly incorporates AI code assistants, a new landscape of security challenges emerges. While AI significantly boosts productivity, it can inadvertently introduce vulnerabilities such as hard-coded secrets, susceptible dependencies, or even dangerous code patterns. This application simulates a developer's workflow at "InnovateTech Solutions," demonstrating a proactive approach to security in AI-assisted development.

The core idea is to integrate security checks early and continuously into the Software Development Lifecycle (SDLC). This involves:
*   **Static Analysis**: Automatically scanning code for common vulnerabilities.
*   **Dependency Assessment**: Analyzing third-party libraries for known risks or suspicious packages.
*   **Automated Security Gates**: Integrating these findings into CI/CD pipelines to block or warn about insecure code.

This application is built upon well-defined **data models** using Pydantic, which are crucial for managing complex security findings efficiently and consistently. These models act as structured blueprints for all the information processed and generated by the application.

*   `GateType` and `FindingType`: These enumerations standardize the categories for security checks and pipeline actions, ensuring clarity and preventing ambiguity in classifying risks.
*   `Severity`: This enumeration allows for consistent prioritization of risks (e.g., `CRITICAL`, `HIGH`, `MEDIUM`, `LOW`), guiding remediation efforts.
*   `CodeArtifact`: Each piece of input code (a snippet or a file) is converted into a structured `CodeArtifact`. This artifact is given a unique ID and a content hash (SHA256). The **content hash** is a cryptographic fingerprint that guarantees the immutability of the code artifact at the time of analysis, which is vital for auditability and incident response.
*   `Finding`: Any security issue discovered is stored as a `Finding` object, complete with its severity, a detailed description, the exact location in the code, and remediation advice.
*   `DependencyRecord`: Information about third-party libraries (e.g., from `requirements.txt`) is structured as `DependencyRecord`s, including their name, version, and status (e.g., `ALLOW`, `DENY`, `UNKNOWN`).
*   `SDLCGatePlan`: The final output, representing the automated CI/CD security controls, is structured to define specific gates and their actions.

These structured models ensure that all data—from input code to final security reports—is consistent, validated, and easily processable, making it invaluable for tracking risks, demonstrating compliance, and automating security policies.

If you haven't run an analysis yet, the application might prompt you to **"Run Analysis with Synthetic Data (Demo)"** on the overview page. This is a great way to immediately see the application in action with pre-loaded example code and data.

## 2. Ingesting Code for Analysis
Duration: 00:03:00

The first practical step in securing your code is to get it into a format that can be analyzed. This involves **ingesting raw code snippets or files** and converting them into standardized `CodeArtifact` records.

This process is critical for establishing a secure baseline. When AI code assistants generate code, you need a precise way to track which specific code was analyzed. If a vulnerability is found, you must be able to link it directly back to the exact version of the code snippet or file that contained it.

The `content_hash` serves as this unalterable reference. It's a cryptographic integrity check, ensuring the code hasn't been tampered with since analysis. For instance, if an auditor later questions a finding, you can provide the hash and the corresponding code, proving the finding's validity against that specific version. The `artifact_id` provides a unique identifier for each piece of code, simplifying tracking across multiple analysis runs.

The SHA256 content hash $H$ for a code artifact $C$ is calculated as:
$$ H = \text{SHA256}(\text{UTF8Encode}(C)) $$
where $H$ is the SHA256 hash and $C$ is the code artifact content. This operation ensures that any change, no matter how small, to the code $C$ will result in a completely different hash $H$, making it an ideal tool for immutability and auditing.

To provide code for analysis:

**Step 1: Tag the Source**
Select who generated the code (e.g., `COPILOT`, `CLAUDE`, `AGENT`, `UNKNOWN`). This metadata helps in understanding the origin of potential risks.

**Step 2: Enter Code**
You have two main options:
*   **Paste a code snippet**: Use the `text_area` to directly paste Python code, `requirements.txt` content, or other text-based code.
*   **Upload files**: Use the `file_uploader` to upload individual code files (like `.py`, `.txt`, `.toml`, `.json`) or even a `.zip` archive containing a full code repository. The application will automatically extract and process files from `.zip` archives.

**Step 3: Run Analysis**
Once you've provided your code, click the **"Analyze Code"** button. The application will then perform static analysis and dependency checks, preparing the data for the next steps. If no code is provided, the application will prompt you to use synthetic data for a demo.

After the analysis completes, you'll see a table of **"Generated Code Artifacts"**, showing the filename, source, and a truncated content hash for each piece of code processed.

## 3. Reviewing Static Analysis Findings
Duration: 00:04:00

After ingesting your code, the application performs a crucial security step: **Static Analysis**. This involves automatically scanning your code for vulnerabilities without actually executing it. The application uses two primary methods:
*   **Regex-based checks**: Simple pattern matching for known insecure strings or patterns (e.g., `API_KEY = "..."`).
*   **AST (Abstract Syntax Tree) analysis**: A more sophisticated technique that understands the structure and logic of your code. This allows for detection of vulnerabilities that regex might miss, such as dangerous function calls (`eval()`, `pickle.loads()`, `subprocess.run(shell=True)`) or insecure cryptographic practices (e.g., MD5 usage).

The **Findings Dashboard** will display a clear overview of all identified vulnerabilities. You'll see critical and high-severity findings, such as:
*   **Hard-coded secrets**: Sensitive information directly embedded in the code.
*   **Potential SQL Injection**: Vulnerabilities that could allow attackers to manipulate database queries.
*   **Dangerous Dynamic Execution**: Use of functions like `eval()` that can execute arbitrary code, leading to Remote Code Execution (RCE).
*   **Unsafe Deserialization**: Functions like `pickle.loads()` that can be exploited to execute malicious code when deserializing untrusted data.
*   **Weak Cryptographic Hashes**: Use of outdated or insecure hashing algorithms like MD5.

For each finding, the dashboard provides:
*   **Severity**: (e.g., CRITICAL, HIGH, MEDIUM, LOW) to help you prioritize.
*   **Finding Type**: The category of the vulnerability (e.g., SECRET, DANGEROUS_FUNCTION, SQL_INJECTION).
*   **Rule ID**: A unique identifier for the specific security rule triggered.
*   **File and Location**: The exact file and line number where the issue was found.
*   **Description**: A detailed explanation of the vulnerability.
*   **Evidence Snippet**: The actual code snippet that triggered the finding, making it easy to pinpoint the issue.
*   **Remediation Guidance**: Practical advice on how to fix the vulnerability.

<aside class="positive">
This immediate feedback helps you understand the security attack surface introduced by AI-generated code and prioritize your remediation efforts. For instance, a `CRITICAL` secret finding would prompt an immediate action to remove the secret and implement a secure secret management solution.
</aside>

The dashboard allows you to filter findings by **Severity** and **Finding Type**, helping you focus on the most pressing issues. Selecting a finding from the list will expand its details, showing the exact code snippet and remediation guidance.

## 4. Assessing Dependency Risks
Duration: 00:03:00

Beyond scanning your own code, a critical aspect of security is ensuring the integrity of your **software supply chain**. AI code assistants can sometimes suggest or include dependencies in `requirements.txt` or `pyproject.toml` files that are:
*   **Outdated**: Containing known vulnerabilities.
*   **Insecure**: Having fundamental design flaws.
*   **Hallucinated**: Entirely fabricated or non-existent packages, which could be malicious or simply lead to broken builds.

The **Dependency Analyzer** helps you mitigate these supply chain risks. It works by:
*   **Parsing Dependency Files**: Extracts package names and versions from files like `requirements.txt` or `pyproject.toml`.
*   **Checking Against Allow/Denylists**: Compares identified packages against your organization's internal `allowlist` (approved packages) and `denylist` (known risky packages).
*   **Detecting Hallucinations**: Applies heuristics (e.g., custom naming patterns) to identify packages that might be AI "hallucinations" – packages that don't exist or have misleading names (like `requests-pro` instead of `requests`).

<aside class="negative">
Detecting hallucinated packages is vital to prevent developers from unknowingly installing malicious or non-functional libraries. This directly prevents supply chain attacks where attackers might register similar-sounding packages to trick developers.
</aside>

The dashboard presents a table of all identified dependencies, showing:
*   **Name** and **Version** of the package.
*   **Status**: Whether it's `ALLOW`, `DENY`, or `UNKNOWN`.
*   **Artifact Filename**: The file from which the dependency was extracted.
*   **Hallucination Risk**: An indicator if the package is suspected to be a hallucination.

You can filter dependencies by their **Status** or choose to **"Show only Hallucination Risks"** to quickly identify packages that need immediate attention.

Understanding and managing these dependencies is key to securing your software. Any package marked as `UNKNOWN` or `DENY` becomes an immediate point of investigation, directly contributing to securing your build process and preventing the introduction of vulnerabilities from third-party libraries.

## 5. Generating Automated Security Gates
Duration: 00:03:00

Identifying vulnerabilities and risks is only the first part of the solution; the next crucial step is to enforce controls to prevent them from reaching production. This is where **CI/CD Gate Plan Generation** comes in. The application translates all the findings and dependency risks into an `sdlc_control_plan.yaml` file that defines specific "gates" for your continuous integration/continuous deployment (CI/CD) pipeline.

These gates are automated checks that will either `BLOCK` a deployment or issue a `WARN` based on the severity and type of findings. This ensures that security is not just an afterthought but an integrated, automated part of your Software Development Lifecycle (SDLC).

The mapping logic for generating the gate plan is as follows:
*   **Presence of `HIGH` or `CRITICAL` findings** (from static analysis): Enforce a `CI_SECURITY` gate with a `BLOCK` action. This means the pipeline will stop if severe vulnerabilities are detected.
*   **Presence of `SECRET` findings**: Enforce a `PRE_COMMIT` secret scanning gate with a `BLOCK` action. This prevents secrets from even being committed to the repository.
*   **Presence of `UNKNOWN` or `DENY` dependencies**: Enforce a `CI_BUILD` or `CI_SECURITY` dependency allowlist gate with a `BLOCK` action. This prevents the use of unapproved or risky third-party libraries.
*   **Otherwise (for lower-risk issues)**: A `WARN` gating action is allowed, which notifies the team without halting the entire development process.

To help drive these decisions, the application can also derive a **risk score** for each code artifact. Let's define a simple risk score for an artifact to drive decision-making for gating, where $S(f)$ is the severity of finding $f$. We assign weights: $\text{Weight}(\text{CRITICAL}) = 100$, $\text{Weight}(\text{HIGH}) = 50$, $\text{Weight}(\text{MEDIUM}) = 10$, $\text{Weight}(\text{LOW}) = 1$.

The `ArtifactRiskScore` for an artifact $A$ is then:
$$ \text{ArtifactRiskScore}(A) = \sum_{f \in \text{Findings}(A)} \text{Weight}(S(f)) $$
where $A$ represents a code artifact, $f$ represents a finding, $S(f)$ is the severity of finding $f$, and $\text{Weight}(S(f))$ is the assigned weight for that severity. This quantitative score helps to aggregate risk across an artifact and inform the gating decision.

The **Gate Plan Generator** page displays a **"Generated CI/CD Gate Plan (YAML Preview)"**. This YAML output provides a clear, machine-readable `sdlc_control_plan.yaml`. You'll observe that based on critical findings (secrets, dangerous execution, denylisted dependencies) identified earlier, the `CI_SECURITY` and `PRE_COMMIT` gates are correctly configured to `BLOCK` the pipeline.

<aside class="positive">
This is where the analysis becomes actionable: if any AI-generated code introduces similar vulnerabilities in the future, your CI/CD pipeline will automatically prevent it from progressing, thus automating security enforcement and building a more resilient development process.
</aside>

## 6. Exporting Auditable Evidence
Duration: 00:02:00

The final stage of this workflow is to consolidate all findings and artifacts into a comprehensive set of **auditable reports**. In a security-conscious organization, clear documentation and auditability are paramount. It's not enough to just find vulnerabilities; you need to provide clear, structured evidence of what was found, where, how it was remediated, and what controls are in place.

These reports are designed to be consumed by different stakeholders:
*   **Developers**: For detailed remediation efforts.
*   **DevSecOps Engineers**: For pipeline configuration and security policy implementation.
*   **Leadership/Auditors**: For risk oversight, compliance demonstration, and integrity verification.

The **Exports & Evidence** page allows you to download these crucial reports:

*   **Findings JSON (`code_gen_risk_findings.json`)**: A detailed, machine-readable list of all identified security findings.
*   **Dependencies JSON (`dependency_risk_report.json`)**: A report on all parsed dependencies, their status, and identified risks.
*   **Gate Plan YAML (`sdlc_control_plan.yaml`)**: The CI/CD gate configuration based on the analysis findings, ready for integration into your pipeline.
*   **Executive Summary Markdown (`case5_executive_summary.md`)**: A high-level, human-readable summary of risks and the control plan for leadership.

Crucially, the application also generates an **`evidence_manifest.json`**. This manifest is an immutable record that cryptographically hashes all inputs and outputs of the analysis. This ensures **non-repudiation** and **integrity** for auditors, providing verifiable proof of the analysis performed.

The `inputs_hash` combines the hashes of all `CodeArtifact` contents. The `outputs_hash` combines the hashes of the generated JSON and YAML reports. This creates a chain of custody for the audit:
$$ \text{inputs\_hash} = \text{SHA256}(\text{Concat}(\text{CodeArtifact}_1.\text{content\_hash}, \dots, \text{CodeArtifact}_N.\text{content\_hash})) $$
$$ \text{outputs\_hash} = \text{SHA256}(\text{Concat}(\text{Hash}(\text{findings.json}), \text{Hash}(\text{deps.json}), \text{Hash}(\text{gateplan.yaml}), \text{Hash}(\text{executive\_summary.md}))) $$
The application will display the calculated **Inputs Hash (SHA256)** and **Outputs Hash (SHA256)** directly on this page.

<aside class="positive">
By generating these comprehensive and auditable reports, you ensure that every step of your security audit is verifiable, transparent, and defensible. This meets strict compliance requirements and solidifies your organization's security posture against the evolving risks of AI-generated code.
</aside>
